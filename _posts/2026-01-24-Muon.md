---
layout:     post
title:      优化器 (2)
subtitle:   Muon
date:       2026-01-24
author:     Zifeng Mai
header-img: img/fuji1.jpg
preview:    本文深入探讨了机器学习优化器的基本原理，从梯度下降开始，逐步深入以SGD和Adam为代表的现代机器学习优化器，展示了其理论基础和工程实践相结合的魅力。此外，本文从动力学的视角理解了某些优化器，可以为读者提供一些新的理解和启发。
catalog: true
tags:
    - Optimizer
    - Kimi
    - Newton-Schulz
    - Optimization Theory
---

## 引言

在上一篇文章中，我们深入介绍了基于梯度下降算法的各种机器学习优化器。这些优化器以SGD和Adam为代表，通过迭代更新模型参数，最小化损失函数。

在实际的机器学习模型中，参数往往是一个矩阵（比如MLP、transformer中的QKV等）。然而在SGD和Adam中，我们一般将参数看作一个一维向量，即 $\theta\in\mathbb{R}^d$，其中 $d$ 是参数的数量。这种强制展平的优化方式忽视了模型的结构。

近期，有一项[研究](https://github.com/KellerJordan/Muon)在社区中引起了不小的关注。这项研究提出了一个全新的优化器Muon (MomentUm Orthogonalized by Newton-Schulz)，这个优化器将参数作为一个矩阵而非向量来看待，因此可以更好地利用参数的结构信息，苏神在博客将这个工作称为【从向量到矩阵的本质跨越】。

在LLM的预训练中，研究者们发现Muon拥有比默认选择AdamW更好的性能，且训练的稳定性更高、收敛速度更快。更重要的是，Muon只需要维护一份梯度的动量估计（Adam需要维护一阶矩和二阶矩），因此在大规模训练中有很大优势。因此，Muon在Kimi-k1.5和Kimi-k2上均被用作预训练阶段的优化器。

在这篇博客中，我们就跟随着苏神的一系列博客，详细介绍Muon优化器的原理和实现。

## 一、Muon的数学原理 [1]

### 1.1. Muon的更新公式

Muon的全称是 "MomentUm Orthogonalized by Newton-Schulz"，从名字中可以看到，Muon的主要创新点是利用Newton-Schulz方法对参数的动量进行正交化。

具体来说，Muon是一个适用于矩阵参数 $W\in\mathbb{R}^{n\times m}$ 的优化器，其更新规则是：

$$
\begin{equation}
    \begin{aligned}
        G_t&=\nabla_{W}\mathcal{J}(W_{t-1})\\
        M_t&=\beta M_{t-1} + G_t\\
        W_t&=W_{t-1} - \eta_t[\text{msign}(M_t)+\lambda W_{t-1}]
    \end{aligned}
    \label{eq:muon_update}
\end{equation}
$$

公式 \eqref{eq:muon_update} 中出现了一个矩阵符号函数 $\text{msign}(M)$，它并不是简单地对矩阵的每个元素进行 $\text{sign}$ 操作，而是 $\text{sign}$ 函数在矩阵上的推广。其定义如下：

$$
\begin{equation}
\begin{aligned}
    U,\Sigma,V^T&=\text{SVD}(M)\\
    \text{msign}(M)&=U_{[:,:r]}V_{[:,:r]}^T
\end{aligned}
\end{equation}
$$

其中，$U\in\mathbb{R}^{n\times n}$、$V\in\mathbb{R}^{m\times m}$ 为正交矩阵，$\Sigma\in\mathbb{R}^{n\times m}$ 为对角矩阵，$r$ 是矩阵 $M$ 的秩。

关于 $\text{msign}(M)$ 的更多理论分析我们后续再进行介绍。在这里我们先对Muon有一个定性的结论，即：“**Muon是一个类似Adam的自适应学习率优化器**”。

在上一篇博客中我们已经看到，像AdaGrad、RMSProp、Adam等自适应学习率优化器的特点是通过维护【梯度平方的滑动平均的平方根】来动态调整每个参数的学习率。这种调节方法有两大好处：

1. 对损失函数进行常数缩放不影响优化轨迹。
2. 每个参数的更新幅度尽可能一致。

而Muon也正好具有这两大好处，具体来说：

1. 当损失函数乘上常数因子 $\lambda$，此时动量矩阵 $M$ 也会乘上相同的因子，但经过SVD分解之后的特征向量矩阵 $UV^T$ 不会发生变化。因此 $\text{msign}(M)$ 不变，即优化轨迹不变。
2. 由于 $\text{msign}(M)$ 是对动量矩阵 $M$ 的正交化，因此它表现出“各向同性”，即每个参数的更新幅度是一致的。

> 事后考古发现，一篇2015年的[论文](https://proceedings.mlr.press/v38/carlson15.html)也提出了类似的思想，当时称为 "Stochastic Spectral Descent"。

### 1.2. 矩阵符号函数

在这一小节中，我们对矩阵符号函数 $\text{msign}(M)$ 的数学性质进行详细介绍。

首先我们说明，为什么它是 $\text{sign}$ 函数在矩阵上的推广。

利用 SVD，我们可以证明（具体证明展示在附录中）：

$$
\begin{equation}
    \begin{aligned}
        \text{msign}(M)&=(MM^T)^{-1/2}M\\
        &=M(M^TM)^{-1/2}
    \end{aligned}
    \label{eq:msign}
\end{equation}
$$

对于实数 $x$，我们有 $\text{sign}(x)=x(x^2)^{-1/2}$。我们可以发现，这二者在形式上式非常相似的。具体来说，当矩阵 $M$ 是一个对角矩阵时，$\text{msign}(M)$ 就等于 $\text{sign}(M)$：

$$
\begin{equation}
    \begin{aligned}
        \text{msign}(M)
        &=\text{diag}(m)\left[\text{diag}(m)^2\right]^{-1/2}\\
        &=\text{diag}\left(\text{sign}(m)\right)\\
        &=\text{sign}(M)
    \end{aligned}
\end{equation}
$$

此外，考虑一维向量 $m\in\mathbb{R}^{n\times 1}$ ，我们有 $\text{msign}(m)=m/\left\|m\right\|_2$，相当于给参数 $m$ 做了L2归一化。

综上所述，Muon对于性质的矩阵参数有着不同的处理方式：

1. 对于一般的矩阵参数（如MLP、QKV等），使用 $\text{msign}(M)$ 对动量进行正交化。
2. 对于对角矩阵参数（如LayerNorm中的gamma），则是对动量进行 $\text{sign}$ 操作。
3. 对于向量参数（如MLP的偏置和词表embedding），则是对动量进行L2归一化。

值得注意的是，虽然词表embedding也属于矩阵参数，但它们在使用上是稀疏的，因此更合理的方式是对它们的动量进行L2归一化。

值得补充的是，当矩阵 $M$ 是一个满秩方阵，即 $m=n=r$ 时，$\text{msign}(M)$ 还可以看作是对矩阵 $M$ 的一个最优正交近似，即：

$$
\begin{equation}
    \text{msign}(M)=\arg\min_{OO^T=I}\|M-O\|_F^2
    \label{eq:msign_opt}
\end{equation}
$$

### 1.3. Newton-schulz迭代求解

由于SVD的计算开销较大，因此在实践中，作者提出了使用Newton-schulz迭代来近似计算 $\text{msign}(M)$。

迭代近似的出发点是公式 \eqref{eq:msign}。不失一般性地，我们设 $n\ge m$。考虑对矩阵函数 $X^{-1/2}$ 在 $X=I$ 处进行二阶泰勒展开得：

$$
\begin{equation}
    \begin{aligned}
        X^{-1/2}
        &\approx I-\frac{1}{2}(X-I)+\frac{3}{8}(X-I)^2\\
        &=\frac{15}{8}-\frac{5}{4}X+\frac{3}{8}X^2
    \end{aligned}
\end{equation}
$$

因此，我们有：

$$
\begin{equation}
    \begin{aligned}
        \text{msign}(M)
        &=M(M^TM)^{-1/2}\\
        &\approx\frac{15}{8}M-\frac{5}{4}M(M^TM)+\frac{3}{8}M(M^TM)^2
    \end{aligned}
\end{equation}
$$

因此，Newton-schulz算法的迭代公式为：

$$
\begin{equation}
    X_{t+1}=\frac{15}{8}X_t-\frac{5}{4}X_t(X_t^TX_t)+\frac{3}{8}X_t(X_t^TX_t)^2
    \label{eq:newton-schulz}
\end{equation}
$$

然而，当我们查看[Muon的官方实现](https://github.com/KellerJordan/Muon/blob/master/muon.py#L16)时，发现其Newton-schulz的迭代公式与公式 \eqref{eq:newton-schulz} 大致相同，但常数项不同。苏神的博客中对这个不一致做出了解释，他认为官方实现对目的在于“**加速收敛**”。感兴趣的读者可以在附录3中找到这个解释的具体内容。



## Appendix

### Apd.1. Proof on Eq. \eqref{eq:msign}

下面我们证明恒等式：

$$
\begin{equation}
    \begin{aligned}
        \text{msign}(M)&=(MM^T)^{-1/2}M\\
        &=M(M^TM)^{-1/2}
    \end{aligned}
\end{equation}
$$

我们首先计算 $MM^T$：

$$
\begin{equation}
    \begin{aligned}
        MM^T
        &=U\Sigma V^T V\Sigma^T U^T\\
        &=U\Sigma\Sigma^T U^T\\
        &=U\Lambda U^T\\
    \end{aligned}
\end{equation}
$$

其中 $\Lambda=\Sigma\Sigma^T\in\mathbb{R}^{n\times n}$ 是对角矩阵，其对角线元素为：

$$
\begin{equation}
    \Lambda_{ii}=
    \begin{cases}
        \sigma_i^2,&i=1,\dots,r\\
        0,&i\gt r
    \end{cases}
\end{equation}
$$

代入恒等式右侧得：

$$
\begin{equation}
\begin{aligned}
    (MM^T)^{-1/2}M
    &=U\Lambda^{-1/2}U^T\cdot U\Sigma V^T\\
    &=U\Lambda^{-1/2}\Sigma V^T\\
\end{aligned}
\end{equation}
$$

其中，$\Lambda^{-1/2}\Sigma$ 是一个对角矩阵，其对角线元素为：

$$
\begin{equation}
    (\Lambda^{-1/2}\Sigma)_{ii}=
    \begin{cases}
        1,&i=1,\dots,r\\
        0,&i\gt r
    \end{cases}
\end{equation}
$$

因此，代入上式得：

$$
\begin{equation}
\begin{aligned}
    (MM^T)^{-1/2}M
    &=U\Lambda^{-1/2}\Sigma V^T\\
    &=U
    \begin{bmatrix}
        I_r&0\\0&0
    \end{bmatrix}
    V^T\\
    &=U_{[:,:r]}V_{[:,:r]}^T\\
    &=\text{msign}(M)
\end{aligned}
\end{equation}
$$

得证。

### Apd.2. Proof on Eq. \eqref{eq:msign_opt}

下面我们证明当矩阵 $M$ 是一个满秩方阵，即 $m=n=r$ 时，有：

$$
\begin{equation}
    \text{msign}(M)=\arg\min_{OO^T=I}\|M-O\|_F^2
\end{equation}
$$

对于正交矩阵 $O$，我们有：

$$
\begin{equation}
    \begin{aligned}
        \|M-O\|_F^2
        &=\|M\|_F^2+\|O\|_F^2-2{\langle M,O\rangle}_F\\
        &=\|M\|_F^2+n-2\text{Tr}(MO^T)\\
        &=\|M\|_F^2+n-2\text{Tr}(U\Sigma V^T O^T)\\
        &=\|M\|_F^2+n-2\text{Tr}(\Sigma V^T O^TU)\\
        &=\|M\|_F^2+n-2\sum_{i=1}^n\Sigma_{ii}\cdot\left(V^T O^TU\right)_{ii}
    \end{aligned}
\end{equation}
$$

由于 $\Sigma_{ii}=\sigma_i\gt 0$，因此我们需要最大化 $\sum_{i=1}^n\Sigma_{ii}\cdot\left(V^T O^TU\right)_{ii}$。

又因为 $V^T O^TU$ 是一个正交矩阵，其对角线元素不超过1。因此当 $V^T O^TU=I$ 时，$\sum_{i=1}^n\Sigma_{ii}\cdot\left(V^T O^TU\right)_{ii}$。最大，即 $\lvert\lvert M-O\rvert\rvert_F^2$ 最小。此时，$O=UV^T=\text{msign}(M)$。

### Apd.3. Newton-schulz迭代的官方实现 [1]

在[Muon的官方实现](https://github.com/KellerJordan/Muon/blob/master/muon.py#L16)中，Newton-schulz迭代的实现为：

$$
\begin{equation}
    X_{t+1}=3.4445X_t-4.7750X_t(X_t^TX_t)+2.0315X_t(X_t^TX_t)^2
\end{equation}
$$

可以看到，所选用的常数项与公式 \eqref{eq:newton-schulz} 不同。在苏神的博客 [1] 中，他认为这样设计是为了加速迭代的收敛速度。下面我们复述一下博客中的内容。

考虑更一般的迭代过程：

$$
\begin{equation}
    X_{t+1}=aX_t+bX_t(X_t^TX_t)+cX_t(X_t^TX_t)^2
    \label{eq:newton-schulz-general}
\end{equation}
$$

其中 $a,b,c$ 是三个待求解的常数项。

我们选择的迭代初始值是 $X_0=M/ \lvert\lvert M\rvert\rvert_F$，之所以要除以F范数，是因为这样子不改变SVD分解得到的正交矩阵 $U,V$，但可以让 $X_0$ 的奇异值都控制在 $[0,1]$ 之间。

设 $U\Sigma_t V^T=\text{SVD}(X_t)$，则代入公式 \eqref{eq:newton-schulz-general} 得：

$$
\begin{equation}
    X_{t+1}=U_{[:,:r]}\left( a\Sigma_{t,[:,:r]}+b\Sigma_{t,[:,:r]}^3+c\Sigma_{t,[:,:r]}^5 \right)V_{[:,:r]}^T
\end{equation}
$$

因此，我们可以看到公式 \eqref{eq:newton-schulz-general} 实际上是在对奇异值对角矩阵 $\Sigma_{t,[:,:r]}$ 进行迭代。这是因为：令 $g(x)=ax+bx^3+cx^5$，则有 $\Sigma_{t+1,[:,:r]}=g(\Sigma_{t,[:,:r]})$。又因为对角阵的幂等于对角线元素各自取幂，所以问题简化成单个奇异值 $\sigma$ 的迭代。

由于我们的目标是将 $X_0=M=U_{[:,:r]}\Sigma U_{[:r,:r]}V_{[:,:r]}^T$ 迭代到 $X_T=\text{msign}(M)=U_{[:,:r]}V_{[:,:r]}^T$，因此我们需要把中间的对角矩阵 $\Sigma U_{[:r,:r]}$ 单位阵 $I$。也就是说，整个迭代过程等价于利用 $x_{t+1}=g(x_t)$ 将实数 $x_0$ 迭代到 $x_T=1$。

我们将常数 $a,b,c$ 的选择视为一个最优化问题，目标是使得迭代过程对于任意初始值 $x_0$ 都能尽可能快地收敛到 $x_T=1$，即迭代步数 $T$ 越小越好。

我们将 $g(x)$ 重新写为：

$$
\begin{equation}
    g(x)=x+\kappa x(x^2-x_1^2)(x^2-x_2^2)
\end{equation}
$$

不失一般性地，我们令 $x_1\le x_2$。这样子我们就能直观地写出 $g(x)$ 的所有不动点：$0, \pm x_1,\pm x_2$。由于我们的目标是收敛到 $x_T=1$，因此作为初始化我们选择 $x_1\lt 1,x_2\gt 1$。只要我们确定好迭代步长 $T$，我们就可以通过优化 $x_T$ 和 $x_0$ 之间的距离，来确定最优的 $a,b,c$。具体来说，我们的求解思路如下：

1. 选定超参数 $n,m,T$。
2. 生成随机矩阵 $M\in\mathbb{R}^{n\times m}$，并计算其SVD分解 $M=U\Sigma V^T$。
3. 初始化 $x_0=\sigma$，并迭代 $T$ 步，得到 $x_T=g^T(x_0)$。
4. 最小化 $(x_T-1)^2$，通过梯度回传求得最优的 $a,b,c$。

我编写了一个[python脚本](https://github.com/Zifeng-Mai/Zifeng-Mai.github.io/blob/master/_appendix/newton-schulz-simulation.py)来进行上述模拟，结论发现：最优参数与矩阵大小、迭代次数 $T$ 都有着明显关系。而Muon官方实现中选择的常数，大概是迭代部署 $T=5$ 时方阵的最优解。

## Reference

[1] [Muon优化器赏析：从向量到矩阵的本质跨越](https://kexue.fm/archives/10592)

